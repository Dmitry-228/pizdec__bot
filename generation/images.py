# generation/images.py
from aiogram.exceptions import TelegramForbiddenError
import re
import aiohttp
import aiofiles
import uuid
import os
import logging
import time
import asyncio
import random
from typing import Optional, List, Dict, Tuple
from aiogram import Bot
from aiogram.types import Message, InputMediaPhoto, InlineKeyboardButton, InlineKeyboardMarkup, FSInputFile
from aiogram.fsm.context import FSMContext
from aiogram.enums import ParseMode
from aiogram.exceptions import TelegramBadRequest
import tenacity
import replicate
from replicate.exceptions import ReplicateError
from deep_translator import GoogleTranslator
from copy import deepcopy

from redis_ca—Åhe import RedisActiveModelCache, RedisGenParamsCache, RedisUserCooldown
from config import REDIS

redis = REDIS
redis_user_cooldown = RedisUserCooldown(redis, cooldown_seconds=3)
redis_active_model_cache = RedisActiveModelCache(redis)
redis_gen_params_cache = RedisGenParamsCache(redis)


from generation_config import (
    IMAGE_GENERATION_MODELS, ASPECT_RATIOS,
    GENERATION_TYPE_TO_MODEL_KEY, MULTI_LORA_MODEL, HF_LORA_MODELS, LORA_CONFIG, LORA_PRIORITIES,
    LORA_STYLE_PRESETS, MAX_LORA_COUNT, USER_AVATAR_LORA_STRENGTH,
    CAMERA_SETUP_BASE, LUXURY_DETAILS_BASE, get_real_lora_model
)
from config import MAX_FILE_SIZE_BYTES, REPLICATE_API_TOKEN, REPLICATE_USERNAME_OR_ORG_NAME, ADMIN_IDS
from database import (
    check_database_user, update_user_credits, get_active_trainedmodel, log_generation, check_user_resources
)
from keyboards import (
    create_main_menu_keyboard, create_rating_keyboard,
    create_subscription_keyboard, create_user_profile_keyboard, create_photo_generate_menu_keyboard
)
from generation.utils import (
    TempFileManager, reset_generation_context,
    send_message_with_fallback, send_photo_with_retry, send_media_group_with_retry
)
from llama_helper import generate_assisted_prompt
from handlers.utils import clean_admin_context, safe_escape_markdown as escape_md

user_last_generation_lock = asyncio.Lock()

logger = logging.getLogger(__name__)

# –°–¢–ê–ù–î–ê–†–¢–ù–´–ï –õ–ò–ú–ò–¢–´
MAX_CONCURRENT_GENERATIONS = 80
REPLICATE_RATE_LIMIT = 40
USER_GENERATION_COOLDOWN = 3

# –°–µ–º–∞—Ñ–æ—Ä—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
generation_semaphore = asyncio.Semaphore(MAX_CONCURRENT_GENERATIONS)
replicate_semaphore = asyncio.Semaphore(REPLICATE_RATE_LIMIT)
download_semaphore = asyncio.Semaphore(80)
file_operation_semaphore = asyncio.Semaphore(150)

# –ö—ç—à–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
cache_lock = asyncio.Lock()
user_generation_lock = {}

# –û—á–µ—Ä–µ–¥—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–π
generation_queue = asyncio.Queue(maxsize=800)
queue_processor_running = False

# –°–£–ü–ï–† –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø (–ò–ó 22 –ü–†–û–§ –ú–û–î–ï–õ–ï–ô)
BASIC_LORA_CONFIG = {
    "base_realism": {
        "model": "prithivMLmods/Flux-Realism-FineDetailed",
        "strength": 0.85,
        "keywords": ["realistic", "detailed", "photographic"],
        "description": "–û—Å–Ω–æ–≤–∞ —Ä–µ–∞–ª–∏–∑–º–∞"
    },
    "face_master": {
        "model": "prithivMLmods/Canopus-LoRA-Flux-FaceRealism",
        "strength": 0.8,
        "keywords": ["face", "portrait", "eyes"],
        "description": "–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ª–∏—Ü"
    },
    "skin_texture": {
        "model": "prithivMLmods/Flux-Skin-Real",
        "strength": 0.9,
        "keywords": ["skin", "texture", "pores"],
        "description": "–¢–µ–∫—Å—Ç—É—Ä–∞ –∫–æ–∂–∏"
    },
    "style_enhance": {
        "model": "alvdansen/frosting_lane_flux",
        "strength": 0.75,
        "keywords": ["style", "professional", "photography"],
        "description": "–°—Ç–∏–ª—å –∏ –æ—Å–≤–µ—â–µ–Ω–∏–µ"
    },
    "fashion_people": {
        "model": "prithivMLmods/Fashion-Hut-Modeling-LoRA",
        "strength": 0.7,
        "keywords": ["fashion", "people", "clothing"],
        "description": "–ú–æ–¥–∞ –∏ –ª—é–¥–∏"
    }
}

# –ë–ê–ó–û–í–´–ï –ü–†–ï–°–ï–¢–´
BASIC_PRESETS = {
    "default": {
        "loras": ["base_realism", "style_enhance"],
        "guidance_scale": 2.5,
        "num_inference_steps": 30,
        "prompt_additions": "professional photography, high quality, detailed, natural lighting"
    },
    "portrait": {
        "loras": ["face_master", "skin_texture", "base_realism"],
        "guidance_scale": 2.6,
        "num_inference_steps": 22,
        "prompt_additions": "portrait photography, professional lighting, sharp focus, natural skin"
    },
    "fashion": {
        "loras": ["fashion_people", "style_enhance", "base_realism"],
        "guidance_scale": 2.4,
        "num_inference_steps": 28,
        "prompt_additions": "fashion photography, magazine quality, professional style"
    }
}

# –ë–ê–ó–û–í–´–ô NEGATIVE PROMPT
BASIC_NEGATIVE_PROMPT = (
    "low quality, bad quality, worst quality, blurry, pixelated, noisy, distorted, "
    "deformed, mutated, ugly, bad anatomy, bad proportions, extra limbs, missing limbs, "
    "bad hands, extra fingers, missing fingers, bad face, distorted face, "
    "watermark, text, logo, signature, username, artist name, "
    "3d render, cartoon, anime, sketch, drawing, painting, artistic, illustration, "
    "cgi, fake, artificial, plastic skin, doll skin, unrealistic"
)

async def process_prompt_async(original_prompt: str, model_key: str, generation_type: str,
                             trigger_word: str = None, selected_gender: str = None,
                             user_input: str = None, user_data: Dict = None,
                             use_new_flux: bool = False) -> str:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø—Ä–æ–º–ø—Ç —Å —É—á–µ—Ç–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞ –∏ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç –µ–≥–æ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π."""

    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–º–ø—Ç–∞: original_prompt='{original_prompt[:50]}...', user_input='{user_input[:50] if user_input else None}...', "
                f"generation_type={generation_type}, trigger_word={trigger_word}, selected_gender={selected_gender}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Llama
    use_llama = user_data.get('use_llama_prompt', False)

    # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–≤–æ–¥ –∏ —ç—Ç–æ –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
    if user_data.get('came_from_custom_prompt') and user_input:
        base_prompt = user_input
        logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç: {base_prompt[:50]}...")
    else:
        base_prompt = original_prompt
        logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {base_prompt[:50]}...")

    # === –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï LLAMA –î–õ–Ø –£–õ–£–ß–®–ï–ù–ò–Ø –ü–†–û–ú–ü–¢–ê ===
    if use_llama and user_input:
        logger.info("ü§ñ –ò—Å–ø–æ–ª—å–∑—É–µ–º Llama –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞")
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–ª –¥–ª—è Llama
            llama_gender = 'person'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if selected_gender:
                if selected_gender.lower() in ['man', 'male']:
                    llama_gender = 'man'
                elif selected_gender.lower() in ['woman', 'female']:
                    llama_gender = 'woman'

            # –í—ã–∑—ã–≤–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞
            enhanced_prompt = await generate_assisted_prompt(
                user_query=user_input,
                gender=llama_gender,
                max_length_chars=1000,
                generation_type=generation_type
            )

            if enhanced_prompt and enhanced_prompt != user_input:
                base_prompt = enhanced_prompt
                logger.info(f"‚ú® Llama —É–ª—É—á—à–∏–ª–∞ –ø—Ä–æ–º–ø—Ç: {base_prompt[:100]}...")
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                if user_data:
                    await user_data.update({'llama_enhanced_prompt': enhanced_prompt})
            else:
                logger.warning("Llama –Ω–µ —Å–º–æ–≥–ª–∞ —É–ª—É—á—à–∏—Ç—å –ø—Ä–æ–º–ø—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Llama: {e}")
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è photo_to_photo
    if generation_type == 'photo_to_photo':
        if use_new_flux and trigger_word:
            base = f"{trigger_word}, copy style from reference image"
            if base_prompt and base_prompt != "copy reference style":
                base += f", {base_prompt}"
            return base + ", natural skin texture, realistic, photographic quality"
        elif trigger_word:
            return f"{trigger_word}, copy style from reference, natural realistic photo"
        else:
            return "copy reference image style, natural realistic photo, authentic"

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    parts = []
    if trigger_word:
        parts.append(trigger_word)

    # –î–æ–±–∞–≤–ª—è–µ–º —É—Å–∏–ª–∏—Ç–µ–ª–∏ —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏–∑–º–∞
    if not user_data.get('came_from_custom_prompt') and not use_llama:
        photorealistic_enhancers = [
            "professional photography",
            "photorealistic",
            "real person",
            "natural skin texture with visible pores",
            "realistic skin tone",
            "authentic human features",
            "not CGI",
            "not 3D render",
            "DSLR camera quality",
            "natural expression",
            "genuine emotion",
            "sharp focus",
            "high resolution"
        ]
        parts.extend(photorealistic_enhancers)

    if selected_gender:
        parts.append(selected_gender)

    parts.append(base_prompt)

    # –î–æ–±–∞–≤–ª—è–µ–º anti_cgi_details —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ù–ï –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ Llama
    if not user_data.get('came_from_custom_prompt') and not use_llama:
        anti_cgi_details = (
            "shot with professional DSLR camera, natural daylight, "
            "real human skin with natural imperfections, "
            "unretouched authentic photography, photojournalism style, "
            "natural hair texture, realistic eye moisture, "
            "genuine facial expression, candid moment, "
            "no artificial enhancement, no beauty filters, "
            "raw unprocessed photo quality"
        )
        parts.append(anti_cgi_details)

    full_prompt = ", ".join(parts)
    full_prompt = re.sub(r'\s+', ' ', full_prompt).strip()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º
    if re.search('[–∞-—è–ê-–Ø]', full_prompt):
        try:
            loop = asyncio.get_event_loop()
            translator = GoogleTranslator(source='auto', target='en')
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            translated_prompt = await loop.run_in_executor(
                None,
                translator.translate,
                full_prompt[:4500]
            )
            if translated_prompt:
                full_prompt = translated_prompt
                logger.info(f"–ü—Ä–æ–º–ø—Ç –ø–µ—Ä–µ–≤–µ–¥–µ–Ω –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π: {full_prompt[:50]}...")
            else:
                logger.warning(f"–ü–µ—Ä–µ–≤–æ–¥ –Ω–µ —É–¥–∞–ª—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {full_prompt[:50]}...")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –ø—Ä–æ–º–ø—Ç–∞: {e}")
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–º–ø—Ç –±–µ–∑ –ø–µ—Ä–µ–≤–æ–¥–∞: {full_prompt[:50]}...")

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –ø—Ä–æ–º–ø—Ç–∞
    if len(full_prompt) > 4000:
        full_prompt = full_prompt[:4000].rsplit(', ', 1)[0]
        logger.warning(f"–ü—Ä–æ–º–ø—Ç –æ–±—Ä–µ–∑–∞–Ω –¥–æ 4000 —Å–∏–º–≤–æ–ª–æ–≤: {full_prompt[:50]}...")

    return full_prompt

async def prepare_model_params(use_new_flux: bool, model_key: str, generation_type: str,
                             prompt: str, num_outputs: int, aspect_ratio: str,
                             width: int, height: int, user_data: Dict) -> Optional[dict]:
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏."""
    logger.info(f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏ (22 –º–æ–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö)")

    reference_image_url = user_data.get('reference_image_url')

    if use_new_flux:
        params = {
            "prompt": prompt,
            "model": "dev",
            "go_fast": True,
            "lora_scale": 0.98,
            "megapixels": "1",
            "num_outputs": num_outputs,
            "aspect_ratio": aspect_ratio,
            "output_format": "png",
            "guidance_scale": 4.5,
            "output_quality": 100,
            "prompt_strength": 0.91,
            "num_inference_steps": 38
        }
        if generation_type == 'photo_to_photo' and reference_image_url:
            params["image"] = reference_image_url
            params["prompt_strength"] = 0.75
    else:
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è LoRA
        params = {
            "prompt": prompt,
            "num_outputs": num_outputs,
            "aspect_ratio": aspect_ratio,
            "lora_scale": 0.98,
            "output_format": "png",
            "guidance_scale": 4.5,
            "width": width,
            "height": height,
            "scheduler": "DDIM",
            "prompt_strength": 0.85,
            "output_quality": 100,
            "num_inference_steps": 40
        }

        # –í—ã–±–∏—Ä–∞–µ–º –±–∞–∑–æ–≤—ã–π –ø—Ä–µ—Å–µ—Ç
        prompt_lower = prompt.lower()
        if any(word in prompt_lower for word in ["face", "portrait", "person", "–ª–∏—Ü–æ", "–ø–æ—Ä—Ç—Ä–µ—Ç"]):
            selected_preset = "portrait"
        elif any(word in prompt_lower for word in ["fashion", "style", "dress", "outfit", "–º–æ–¥–∞"]):
            selected_preset = "fashion"
        else:
            selected_preset = "default"

        preset = BASIC_PRESETS.get(selected_preset, BASIC_PRESETS["default"])
        params["guidance_scale"] = preset["guidance_scale"]
        params["num_inference_steps"] = preset["num_inference_steps"]

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è
        if not user_data.get('came_from_custom_prompt'):
            params["prompt"] = f"{prompt}, {preset['prompt_additions']}"

        # –î–æ–±–∞–≤–ª—è–µ–º –º–æ–¥–µ–ª–∏
        lora_index = 3

        # –î–æ–±–∞–≤–ª—è–µ–º –∞–≤–∞—Ç–∞—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if generation_type in ['with_avatar', 'photo_to_photo']:
            trigger_word = user_data.get('trigger_word')
            old_model_id = user_data.get('old_model_id')
            old_model_version = user_data.get('old_model_version')
            if trigger_word and old_model_version:
                if old_model_id:
                    if '/' not in old_model_id:
                        avatar_lora = f"{REPLICATE_USERNAME_OR_ORG_NAME}/{old_model_id}:{old_model_version}"
                    else:
                        avatar_lora = f"{old_model_id}:{old_model_version}"
                    params[f"hf_lora_{lora_index}"] = avatar_lora
                    params[f"lora_scale_{lora_index}"] = USER_AVATAR_LORA_STRENGTH
                    lora_index += 1
                    logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∞–≤–∞—Ç–∞—Ä (LoRA #{lora_index-1})")

        # –î–æ–±–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—ã–µ LoRA
        if not user_data.get('came_from_custom_prompt'):
            for lora_name in preset.get("loras", []):
                if lora_index <= MAX_LORA_COUNT:
                    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ 5 –±–∞–∑–æ–≤—ã—Ö
                    lora_cfg = get_real_lora_model(lora_name)
                    if lora_cfg and "model" in lora_cfg:
                        params[f"hf_lora_{lora_index}"] = lora_cfg["model"]
                        params[f"lora_scale_{lora_index}"] = lora_cfg["strength"]
                        logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å {lora_name} (LoRA #{lora_index})")
                        lora_index += 1

        params["negative_prompt"] = BASIC_NEGATIVE_PROMPT

        if generation_type == 'photo_to_photo' and reference_image_url:
            params["image"] = reference_image_url
            params["strength"] = 0.75

        logger.info(f"=== –ü–ê–†–ê–ú–ï–¢–†–´ –ì–ï–ù–ï–†–ê–¶–ò–ò ===")
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {lora_index - 1} –º–æ–¥–µ–ª–µ–π –∏–∑ 22 –¥–æ—Å—Ç—É–ø–Ω—ã—Ö")
        logger.info(f"Preset: {selected_preset}")
        logger.info(f"Guidance Scale: {params['guidance_scale']}")
        logger.info(f"Inference Steps: {params['num_inference_steps']}")

    return params

async def start_queue_processor():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—á–µ—Ä–µ–¥–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π"""
    global queue_processor_running
    if not queue_processor_running:
        queue_processor_running = True
        for i in range(15):
            asyncio.create_task(process_generation_queue(i))
        logger.info("–ó–∞–ø—É—â–µ–Ω—ã –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –æ—á–µ—Ä–µ–¥–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π")

async def process_generation_queue(worker_id: int):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—á–µ—Ä–µ–¥–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π"""
    while True:
        try:
            task = await generation_queue.get()
            if task is None:
                break
            message, state, num_outputs = task
            try:
                await _generate_image_internal(message, state, num_outputs)
            except Exception as e:
                logger.error(f"Worker {worker_id}: –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}", exc_info=True)
            finally:
                generation_queue.task_done()
        except Exception as e:
            logger.error(f"Worker {worker_id}: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ –æ—á–µ—Ä–µ–¥–∏: {e}", exc_info=True)
            await asyncio.sleep(1)

async def get_user_generation_lock(user_id: int):
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫—É –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    if user_id not in user_generation_lock:
        user_generation_lock[user_id] = asyncio.Lock()
    return user_generation_lock[user_id]

async def check_user_cooldown(user_id: int) -> bool:
    if await redis_user_cooldown.is_on_cooldown(user_id):
        return False 
    await redis_user_cooldown.set_cooldown(user_id)
    return True


async def get_active_model_cached(user_id: int):
    """–ü–æ–ª—É—á–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º —á–µ—Ä–µ–∑ Redis"""
    cached = await redis_active_model_cache.get(user_id)
    if cached:
        return cached
    model_data = await get_active_trainedmodel(user_id)
    await redis_active_model_cache.set(user_id, model_data)
    return model_data

async def clear_avatar_cache(user_id: int) -> None:
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—á–∏—â–∞–µ—Ç –∫—ç—à –∞–≤–∞—Ç–∞—Ä–æ–≤ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ Redis"""
    await redis_active_model_cache.set(user_id, None)
    logger.info(f"Redis-–∫—ç—à –∞–≤–∞—Ç–∞—Ä–æ–≤ –æ—á–∏—â–µ–Ω –¥–ª—è user_id={user_id}")


async def download_image_async(session: aiohttp.ClientSession, url: str, filepath: str, retry_count: int = 3) -> Optional[str]:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    async with download_semaphore:
        for attempt in range(retry_count):
            try:
                timeout = aiohttp.ClientTimeout(total=30)
                async with session.get(url, timeout=timeout) as response:
                    if response.status == 200:
                        os.makedirs(os.path.dirname(filepath), exist_ok=True)
                        async with aiofiles.open(filepath, 'wb') as f:
                            async for chunk in response.content.iter_chunked(8192):
                                await f.write(chunk)
                        logger.debug(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª: {filepath}")
                        return filepath
                    else:
                        logger.warning(f"HTTP {response.status} –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url}")
            except asyncio.TimeoutError:
                logger.warning(f"–¢–∞–π–º–∞—É—Ç –∑–∞–≥—Ä—É–∑–∫–∏ {url}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retry_count}")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")

            if attempt < retry_count - 1:
                await asyncio.sleep(1 * (attempt + 1))

        return None

async def download_images_parallel(urls: List[str], user_id: int) -> List[str]:
    """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    paths = []
    tasks = []

    connector = aiohttp.TCPConnector(limit=15, limit_per_host=8)
    timeout = aiohttp.ClientTimeout(total=60)

    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        for i, url in enumerate(urls):
            filepath = f"generated/{user_id}_{uuid.uuid4().hex[:8]}_{i}.png"
            task = download_image_async(session, url, filepath)
            tasks.append(task)

        results = await asyncio.gather(*tasks, return_exceptions=True)

        for result in results:
            if isinstance(result, str) and result:
                paths.append(result)
            elif isinstance(result, Exception):
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {result}")

    return paths

async def generate_image(message: Message, state: FSMContext, num_outputs: int = 2, user_id: int = None) -> None:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å 22 –º–æ–¥–µ–ª—è–º–∏"""
    user_data = await state.get_data()
    bot = message.bot
    bot_id = (await bot.get_me()).id
    user_id = user_id or message.from_user.id

    logger.info(f"=== –ì–ï–ù–ï–†–ê–¶–ò–Ø –ù–ê–ß–ê–õ–ê–°–¨ (22 –º–æ–¥–µ–ª–∏) ===")
    logger.info(f"–ò–Ω–∏—Ü–∏–∞—Ç–æ—Ä: {user_id}")

    is_admin_generation = user_data.get('is_admin_generation', False)
    admin_generation_for_user = user_data.get('admin_generation_for_user')
    admin_user_id = user_data.get('original_admin_user', user_id)

    if is_admin_generation and admin_generation_for_user and user_id in ADMIN_IDS:
        message_recipient = admin_user_id
        target_user_id = admin_generation_for_user
        if target_user_id == bot_id:
            logger.error(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π target_user_id: {target_user_id}")
            await send_message_with_fallback(
                bot, admin_user_id,
                escape_md("‚ùå –û—à–∏–±–∫–∞: –Ω–µ–≤–µ—Ä–Ω—ã–π ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.", version=2),
                reply_markup=await create_main_menu_keyboard(admin_user_id),
                parse_mode=ParseMode.MARKDOWN_V2
            )
            return
        logger.info(f"–ê–î–ú–ò–ù–°–ö–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø: –∞–¥–º–∏–Ω={message_recipient}, —Ü–µ–ª—å={target_user_id}")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –∞–≤–∞—Ç–∞—Ä–∞ –¥–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        trained_model_data = await get_active_model_cached(target_user_id)
        if trained_model_data and trained_model_data[3] == 'success':
            await state.update_data(
                trigger_word=trained_model_data[5],
                model_version=trained_model_data[2],
                old_model_id=trained_model_data[4],
                old_model_version=trained_model_data[0],
                active_avatar_name=trained_model_data[8]
            )
    else:
        message_recipient = user_id
        target_user_id = user_id
        logger.info(f"–û–ë–´–ß–ù–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å={target_user_id}")
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∞–¥–º–∏–Ω—Å–∫–∏–µ –ø–æ–ª—è
        admin_fields = [
            'is_admin_generation', 'admin_generation_for_user',
            'admin_target_user_id', 'giving_sub_to_user',
            'broadcast_type', 'awaiting_broadcast_message',
            'awaiting_search_query', 'admin_view_source'
        ]
        await state.update_data({field: None for field in admin_fields})

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    required_fields = ['prompt', 'aspect_ratio', 'generation_type', 'model_key']
    missing_fields = [field for field in required_fields if not user_data.get(field)]

    if missing_fields:
        logger.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–æ–ª—è: {missing_fields}")
        await send_message_with_fallback(
            bot, message_recipient,
            f"‚ö†Ô∏è –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã—Ö: {', '.join(missing_fields)}. –ù–∞—á–Ω–∏ –∑–∞–Ω–æ–≤–æ —á–µ—Ä–µ–∑ /menu.",
            reply_markup=await create_main_menu_keyboard(message_recipient),
            parse_mode=ParseMode.MARKDOWN_V2
        )
        return

    await start_queue_processor()

    if not await check_user_cooldown(message_recipient):
        await send_message_with_fallback(
            bot, message_recipient,
            "‚è≥ –ü–æ–¥–æ–∂–¥–∏ –ø–∞—Ä—É —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π!",
            parse_mode=ParseMode.MARKDOWN_V2
        )
        return

    generation_type = user_data.get('generation_type')
    if generation_type == 'with_avatar':
        required_photos = num_outputs
    elif generation_type == 'photo_to_photo':
        required_photos = 2
    else:
        required_photos = 1

    if not is_admin_generation:
        logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è user_id={target_user_id}, —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ñ–æ—Ç–æ: {required_photos}")
        if not await check_user_resources(bot, target_user_id, required_photos=required_photos):
            return

    if generation_queue.full():
        await send_message_with_fallback(
            bot, message_recipient,
            "üòî –°–µ—Ä–≤–µ—Ä –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω! –ü–æ–ø—Ä–æ–±—É–π —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É.",
            reply_markup=await create_main_menu_keyboard(message_recipient),
            parse_mode=ParseMode.MARKDOWN_V2
        )
        return

    try:
        generation_data = deepcopy({
            'prompt': user_data.get('prompt'),
            'aspect_ratio': user_data.get('aspect_ratio'),
            'generation_type': user_data.get('generation_type'),
            'model_key': user_data.get('model_key'),
            'selected_gender': user_data.get('selected_gender'),
            'user_input_for_llama': user_data.get('user_input_for_llama'),
            'trigger_word': user_data.get('trigger_word'),
            'model_version': user_data.get('model_version'),
            'old_model_id': user_data.get('old_model_id'),
            'old_model_version': user_data.get('old_model_version'),
            'reference_image_url': user_data.get('reference_image_url'),
            'photo_path': user_data.get('photo_path'),
            'message_recipient': message_recipient,
            'generation_target_user': target_user_id,
            'original_admin_user': admin_user_id,
            'is_admin_generation': is_admin_generation,
            'admin_generation_for_user': admin_generation_for_user,
            'photos_to_deduct': required_photos if not is_admin_generation else 0,
            'current_style_set': user_data.get('current_style_set'),
            'came_from_custom_prompt': user_data.get('came_from_custom_prompt', False),
            'use_llama_prompt': user_data.get('use_llama_prompt', False),
            'last_generation_params': user_data.get('last_generation_params'),
            'active_avatar_name': user_data.get('active_avatar_name')
        })

        await state.update_data(generation_data)
        await generation_queue.put((message, state, num_outputs))

        queue_size = generation_queue.qsize()
        if queue_size > 10:
            if is_admin_generation:
                message_text = f"üìä –ó–∞–ø—Ä–æ—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {target_user_id} –¥–æ–±–∞–≤–ª–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å (–ø–æ–∑–∏—Ü–∏—è: ~{queue_size})."
            else:
                message_text = f"üìä –¢–≤–æ–π –∑–∞–ø—Ä–æ—Å –¥–æ–±–∞–≤–ª–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å (–ø–æ–∑–∏—Ü–∏—è: ~{queue_size}). –û–∂–∏–¥–∞–π —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è!"
            await send_message_with_fallback(
                bot, message_recipient,
                message_text,
                parse_mode=ParseMode.MARKDOWN_V2
            )

        logger.info(f"‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –æ—á–µ—Ä–µ–¥—å: recipient={message_recipient}, target={target_user_id}")

    except asyncio.QueueFull:
        logger.error(f"–û—á–µ—Ä–µ–¥—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞ –¥–ª—è user_id={message_recipient}")
        await send_message_with_fallback(
            bot, message_recipient,
            "üòî –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –≤ –æ—á–µ—Ä–µ–¥—å. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑!",
            reply_markup=await create_main_menu_keyboard(message_recipient),
            parse_mode=ParseMode.MARKDOWN_V2
        )
    except Exception as e:
        logger.error(f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ generate_image: {e}", exc_info=True)
        await send_message_with_fallback(
            bot, message_recipient,
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            reply_markup=await create_main_menu_keyboard(message_recipient),
            parse_mode=ParseMode.MARKDOWN_V2
        )

async def _generate_image_internal(message: Message, state: FSMContext, num_outputs: int = 2) -> None:
    """–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å 5 –±–∞–∑–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏)"""
    from handlers.generation import handle_admin_generation_result

    async with asyncio.Lock():
        user_data = await state.get_data()
        message_recipient = user_data.get('message_recipient', message.from_user.id)
        target_user_id = user_data.get('generation_target_user', message.from_user.id)
        admin_user_id = user_data.get('original_admin_user', message.from_user.id)
        is_admin_generation = user_data.get('is_admin_generation', False)
        bot = message.bot
        bot_id = (await bot.get_me()).id

        preserved_data = {}

        if message_recipient == bot_id or target_user_id == bot_id:
            logger.error(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π ID –ø–æ–ª—É—á–∞—Ç–µ–ª—è –∏–ª–∏ —Ü–µ–ª–∏")
            return

        logger.info(f"=== –í–ù–£–¢–†–ï–ù–ù–Ø–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø (22 –º–æ–¥–µ–ª–∏) ===")
        logger.info(f"message_recipient={message_recipient}, target_user_id={target_user_id}")

        start_time = time.time()
        user_lock = await get_user_generation_lock(target_user_id)

        async with user_lock:
            async with generation_semaphore:
                logger.info(f"üéØ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–ª—è user_id={target_user_id} —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã")

                subscription_data = await check_database_user(target_user_id)
                if not isinstance(subscription_data, tuple) or len(subscription_data) < 9:
                    logger.error(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥–ø–∏—Å–∫–∏ –¥–ª—è user_id={target_user_id}")
                    await send_message_with_fallback(
                        bot, message_recipient,
                        escape_md("‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞! –ü–æ–ø—Ä–æ–±—É–π /menu.", version=2),
                        reply_markup=await create_main_menu_keyboard(message_recipient),
                        parse_mode=ParseMode.MARKDOWN_V2
                    )
                    return

                generation_type = user_data.get('generation_type')
                prompt = user_data.get('prompt')
                aspect_ratio_key = user_data.get('aspect_ratio')
                model_key = user_data.get('model_key')
                style_name = user_data.get('style_name', '–ö–∞—Å—Ç–æ–º–Ω—ã–π —Å—Ç–∏–ª—å')

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
                missing_critical = []
                if not generation_type:
                    missing_critical.append('generation_type')
                if not prompt:
                    missing_critical.append('prompt')
                if not aspect_ratio_key:
                    missing_critical.append('aspect_ratio')
                if not model_key:
                    missing_critical.append('model_key')

                if missing_critical:
                    logger.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–ª—é—á–µ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ: {missing_critical}")
                    await send_message_with_fallback(
                        bot, message_recipient,
                        escape_md("‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –¥–∞–Ω–Ω—ã—Ö. –ù–∞—á–Ω–∏ –∑–∞–Ω–æ–≤–æ —á–µ—Ä–µ–∑ /menu.", version=2),
                        reply_markup=await create_main_menu_keyboard(message_recipient),
                        parse_mode=ParseMode.MARKDOWN_V2
                    )
                    return

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–≤–∞—Ç–∞—Ä–∞ –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ç–∏–ø–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                if generation_type in ['with_avatar', 'photo_to_photo']:
                    trained_model_data = await get_active_model_cached(target_user_id)
                    if not trained_model_data or trained_model_data[3] != 'success':
                        logger.error(f"–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–≤–∞—Ç–∞—Ä–∞ –¥–ª—è target_user_id={target_user_id}")
                        await send_message_with_fallback(
                            bot, message_recipient,
                            escape_md("‚ùå –ê–∫—Ç–∏–≤–Ω—ã–π –∞–≤–∞—Ç–∞—Ä –Ω–µ –≥–æ—Ç–æ–≤! –°–æ–∑–¥–∞–π –µ–≥–æ –≤ –õ–∏—á–Ω–æ–º –∫–∞–±–∏–Ω–µ—Ç–µ.", version=2),
                            reply_markup=await create_user_profile_keyboard(message_recipient, bot),
                            parse_mode=ParseMode.MARKDOWN_V2
                        )
                        await reset_generation_context(state, generation_type)
                        return

                required_photos = user_data.get('photos_to_deduct', num_outputs)

                if not is_admin_generation:
                    logger.info(f"–°–ø–∏—Å–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è user_id={target_user_id}, —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ñ–æ—Ç–æ: {required_photos}")
                    await update_user_credits(target_user_id, "decrement_photo", amount=required_photos)

                selected_gender = user_data.get('selected_gender')
                user_input_for_helper = user_data.get('user_input_for_llama')

                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∞–≤–∞—Ç–∞—Ä–∞
                if generation_type in ['with_avatar', 'photo_to_photo']:
                    trained_model_data = await get_active_model_cached(target_user_id)
                    if trained_model_data and trained_model_data[3] == 'success':
                        await state.update_data(
                            trigger_word=trained_model_data[5],
                            model_version=trained_model_data[2],
                            old_model_id=trained_model_data[4],
                            old_model_version=trained_model_data[0],
                            active_avatar_name=trained_model_data[8]
                        )

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                generation_params = {
                    'prompt': prompt,
                    'aspect_ratio': aspect_ratio_key,
                    'generation_type': generation_type,
                    'model_key': model_key,
                    'selected_gender': selected_gender,
                    'user_input_for_llama': user_input_for_helper,
                    'style_name': style_name,
                    'current_style_set': user_data.get('current_style_set'),
                    'came_from_custom_prompt': user_data.get('came_from_custom_prompt', False),
                    'use_llama_prompt': user_data.get('use_llama_prompt', False),
                    'duration': 0.0
                }

                preserved_data['last_generation_params'] = generation_params

                if model_key not in IMAGE_GENERATION_MODELS:
                    logger.error(f"–ù–µ–≤–µ—Ä–Ω—ã–π model_key: {model_key}")
                    await send_message_with_fallback(
                        bot, message_recipient,
                        escape_md("‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏!", version=2),
                        reply_markup=await create_main_menu_keyboard(message_recipient),
                        parse_mode=ParseMode.MARKDOWN_V2
                    )
                    await reset_generation_context(state, generation_type)
                    return

                model_config = IMAGE_GENERATION_MODELS[model_key]
                replicate_model_id_to_run = model_config['id']
                trigger_word = user_data.get('trigger_word')
                use_new_flux_method = False

                # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –∞–≤–∞—Ç–∞—Ä–æ–º
                if generation_type in ['with_avatar', 'photo_to_photo']:
                    trained_model_data = await get_active_model_cached(target_user_id)
                    if not trained_model_data or trained_model_data[3] != 'success':
                        logger.error(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –∞–≤–∞—Ç–∞—Ä –Ω–µ –≥–æ—Ç–æ–≤ –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏!")
                        await send_message_with_fallback(
                            bot, message_recipient,
                            escape_md("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –∞–≤–∞—Ç–∞—Ä –Ω–µ –≥–æ—Ç–æ–≤!", version=2),
                            reply_markup=await create_user_profile_keyboard(message_recipient, bot),
                            parse_mode=ParseMode.MARKDOWN_V2
                        )
                        await reset_generation_context(state, generation_type)
                        return

                    avatar_id, model_id, model_version, status, prediction_id, trigger_word, photo_paths, training_step, avatar_name = trained_model_data
                    await state.update_data(trigger_word=trigger_word, model_version=model_version, active_avatar_name=avatar_name)

                    is_fast_flux = is_new_fast_flux_model(model_id, model_version)
                    if is_fast_flux:
                        use_new_flux_method = True
                        if model_version:
                            if '/' not in model_id:
                                replicate_model_id_to_run = f"{REPLICATE_USERNAME_OR_ORG_NAME}/{model_id}:{model_version}"
                            else:
                                replicate_model_id_to_run = f"{model_id}:{model_version}"
                        else:
                            if '/' not in model_id:
                                replicate_model_id_to_run = f"{REPLICATE_USERNAME_OR_ORG_NAME}/{model_id}"
                            else:
                                replicate_model_id_to_run = model_id
                        logger.info(f"Using Fast Flux model: {replicate_model_id_to_run}")
                    else:
                        use_new_flux_method = False
                        replicate_model_id_to_run = MULTI_LORA_MODEL
                        logger.info(f"Using Multi-LoRA model (–ú–æ–¥–µ–ª–∏): {replicate_model_id_to_run}")
                        await state.update_data(old_model_id=model_id, old_model_version=model_version)

                generation_message = await send_message_with_fallback(
                    bot, message_recipient,
                    escape_md(f"üì∏ –°–æ–∑–¥–∞—é {num_outputs} —Ñ–æ—Ç–æ —Å –ø–æ–º–æ—â—å—é –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –ò–ò –º–æ–¥–µ–ª–µ–π! –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞...", version=2),
                    parse_mode=ParseMode.MARKDOWN_V2
                )

                try:
                    user_data = await state.get_data()
                    processed_prompt = await process_prompt_async(
                        prompt, model_key, generation_type,
                        trigger_word, selected_gender, user_input_for_helper, user_data,
                        use_new_flux=use_new_flux_method
                    )

                    width, height = ASPECT_RATIOS.get(aspect_ratio_key, (1024, 1024))

                    input_params = await prepare_model_params(
                        use_new_flux_method, model_key, generation_type,
                        processed_prompt, num_outputs, aspect_ratio_key,
                        width, height, user_data
                    )

                    if input_params is None:
                        if isinstance(generation_message, Message):
                            await generation_message.delete()
                        await send_message_with_fallback(
                            bot, message_recipient,
                            escape_md("‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤!", version=2),
                            reply_markup=await create_main_menu_keyboard(message_recipient),
                            parse_mode=ParseMode.MARKDOWN_V2
                        )
                        await reset_generation_context(state, generation_type)
                        return

                    await log_generation(
                        target_user_id,
                        generation_type,
                        replicate_model_id_to_run,
                        num_outputs
                    )

                    if isinstance(generation_message, Message):
                        await generation_message.edit_text(
                            escape_md(
                                f"üéØ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –≤–∞—à–∏ —Ñ–æ—Ç–æ —Å –ø–æ–º–æ—â—å—é PixelPie_AI.\n"
                                f"üì∏ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω–∞—è –ò–ò –Ω–µ–π—Ä–æ—Å–µ—Ç—å!\n"
                                f"‚ö° PixelPie_AI —Å–æ–∑–¥–∞–µ—Ç –≤–∞—à —à–µ–¥–µ–≤—Ä!", version=2
                            ),
                            parse_mode=ParseMode.MARKDOWN_V2
                        )

                    async with replicate_semaphore:
                        image_urls = await run_replicate_model_async(replicate_model_id_to_run, input_params)

                    if not image_urls:
                        logger.error("–ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç Replicate")
                        if isinstance(generation_message, Message):
                            await generation_message.edit_text(
                                escape_md("‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏! –ü–æ–ø—Ä–æ–±—É–π —Å–Ω–æ–≤–∞.", version=2),
                                reply_markup=await create_main_menu_keyboard(message_recipient),
                                parse_mode=ParseMode.MARKDOWN_V2
                            )
                        await reset_generation_context(state, generation_type)
                        return

                    if isinstance(generation_message, Message):
                        await generation_message.edit_text(
                            escape_md("‚úÖ –ì–æ—Ç–æ–≤–æ! –ó–∞–≥—Ä—É–∂–∞—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...", version=2),
                            parse_mode=ParseMode.MARKDOWN_V2
                        )

                    image_paths = await download_images_parallel(image_urls, target_user_id)

                    if not image_paths:
                        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                        if isinstance(generation_message, Message):
                            await generation_message.edit_text(
                                escape_md("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏! –ü–µ—á–µ–Ω—å–∫–∏ –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã.", version=2),
                                reply_markup=await create_main_menu_keyboard(message_recipient),
                                parse_mode=ParseMode.MARKDOWN_V2
                            )
                        if not is_admin_generation:
                            await update_user_credits(target_user_id, "increment_photo", amount=required_photos)
                        await reset_generation_context(state, generation_type)
                        return

                    duration = time.time() - start_time

                    try:
                        if isinstance(generation_message, Message):
                            await generation_message.delete()
                    except:
                        pass

                    # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                    generation_params.update({'image_urls': image_urls, 'duration': duration})
                    preserved_data.update({
                        'last_generation_params': generation_params,
                    })

                    if is_admin_generation:
                        preserved_data.update({
                            'is_admin_generation': True,
                            'admin_generation_for_user': target_user_id,
                            'message_recipient': admin_user_id,
                            'generation_target_user': target_user_id,
                            'original_admin_user': admin_user_id
                        })

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–µ—Ä–µ–¥ –æ—á–∏—Å—Ç–∫–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                    await state.update_data(**preserved_data)

                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                    if is_admin_generation:
                        result_data = {
                            'success': True,
                            'image_urls': image_urls,
                            'prompt': processed_prompt,
                            'style': user_data.get('style_name', 'custom')
                        }
                        await handle_admin_generation_result(state, admin_user_id, target_user_id, result_data, bot)
                    else:
                        await send_generation_results(
                            bot, message_recipient, target_user_id, image_paths, duration, aspect_ratio_key,
                            generation_type, model_key, state, admin_user_id if is_admin_generation else None
                        )

                    logger.info(f"üéØ PixelPie_AI –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è user_id={target_user_id}: "
                               f"{len(image_paths)} —Ñ–æ—Ç–æ –∑–∞ {duration:.1f} —Å–µ–∫ (22 –º–æ–¥–µ–ª–∏)")

                    asyncio.create_task(cleanup_files(image_paths + [user_data.get('photo_path')]))

                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è user_id={target_user_id}: {e}", exc_info=True)
                    error_message = escape_md("‚ùå –û—à–∏–±–∫–∞! –ü–µ—á–µ–Ω—å–∫–∏ –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã –Ω–∞ –±–∞–ª–∞–Ω—Å.", version=2)
                    if isinstance(generation_message, Message):
                        try:
                            await generation_message.edit_text(
                                error_message,
                                reply_markup=await create_main_menu_keyboard(message_recipient),
                                parse_mode=ParseMode.MARKDOWN_V2
                            )
                        except:
                            await send_message_with_fallback(
                                bot, message_recipient,
                                error_message,
                                reply_markup=await create_main_menu_keyboard(message_recipient),
                                parse_mode=ParseMode.MARKDOWN_V2
                            )
                    if not is_admin_generation:
                        await update_user_credits(target_user_id, "increment_photo", amount=required_photos)
                    await reset_generation_context(state, generation_type)
                finally:
                    if preserved_data:
                        await state.update_data(**preserved_data)
                    await clean_admin_context(state)
                    logger.info("–ê–¥–º–∏–Ω—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω –ø–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")

async def send_generation_results(bot: Bot, message_recipient: int, target_user_id: int,
                                image_paths: List[str], duration: float, aspect_ratio: str,
                                generation_type: str, model_key: str, state: FSMContext,
                                admin_user_id: int = None) -> None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é"""
    user_data = await state.get_data()
    state_value = user_data.get('state')

    try:
        if len(image_paths) == 1:
            caption = escape_md(f"üì∏ –í–∞—à–∞ –ò–ò –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –≥–æ—Ç–æ–≤–∞! –í—Ä–µ–º—è: {duration:.1f} —Å–µ–∫", version=2)
            photo_file = FSInputFile(path=image_paths[0])
            await send_photo_with_retry(
                bot, message_recipient, photo_file, caption=caption,
                reply_markup=await create_rating_keyboard(generation_type, model_key, message_recipient, bot),
                parse_mode=ParseMode.MARKDOWN_V2
            )
            if admin_user_id and admin_user_id != message_recipient:
                await bot.send_photo(
                    chat_id=admin_user_id,
                    photo=photo_file,
                    caption=escape_md(f"–§–æ—Ç–æ –¥–ª—è ID {target_user_id}", version=2),
                    reply_markup=InlineKeyboardMarkup(inline_keyboard=[[
                        InlineKeyboardButton(text="üîô –ö –¥–µ–π—Å—Ç–≤–∏—è–º", callback_data=f"user_actions_{target_user_id}")
                    ]]),
                    parse_mode=ParseMode.MARKDOWN_V2
                )
        else:
            caption = escape_md(
                f"üì∏ {len(image_paths)} –í–∞—à–∏—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π —Å–æ–∑–¥–∞–Ω—ã! ({duration:.1f} —Å–µ–∫)\n"
                f"üéØ –°–¥–µ–ª–∞–Ω–æ –ø—Ä–∏ –ø–æ–º–æ—â–∏ PixelPie_AI", version=2
            )
            media = []
            for i, path in enumerate(image_paths):
                photo_file = FSInputFile(path=path)
                if i == 0:
                    media.append(InputMediaPhoto(media=photo_file, caption=caption, parse_mode=ParseMode.MARKDOWN_V2))
                else:
                    media.append(InputMediaPhoto(media=photo_file))

            await send_media_group_with_retry(bot, message_recipient, media)
            await send_message_with_fallback(
                bot, message_recipient,
                escape_md("‚≠ê –û—Ü–µ–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ò–ò —Ñ–æ—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:", version=2),
                reply_markup=await create_rating_keyboard(generation_type, model_key, message_recipient, bot),
                parse_mode=ParseMode.MARKDOWN_V2
            )

            if admin_user_id and admin_user_id != message_recipient:
                await send_media_group_with_retry(bot, admin_user_id, media)
                await bot.send_message(
                    chat_id=admin_user_id,
                    text=escape_md(f"–§–æ—Ç–æ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {target_user_id} –≥–æ—Ç–æ–≤—ã", version=2),
                    reply_markup=InlineKeyboardMarkup(inline_keyboard=[[
                        InlineKeyboardButton(text="üîô –ö –¥–µ–π—Å—Ç–≤–∏—è–º", callback_data=f"user_actions_{target_user_id}")
                    ]]),
                    parse_mode=ParseMode.MARKDOWN_V2
                )

        await state.clear()
        if state_value:
            await state.update_data(state=state_value)

        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –¥–ª—è user_id={message_recipient}")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ send_generation_results: {e}", exc_info=True)
        await send_message_with_fallback(
            bot, message_recipient,
            escape_md("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É: @AXIDI_Help", version=2),
            reply_markup=await create_main_menu_keyboard(message_recipient),
            parse_mode=ParseMode.MARKDOWN_V2
        )

async def cleanup_files(filepaths: List[Optional[str]]):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    for filepath in filepaths:
        if filepath and os.path.exists(filepath):
            try:
                async with file_operation_semaphore:
                    await asyncio.get_event_loop().run_in_executor(None, os.remove, filepath)
                logger.debug(f"–£–¥–∞–ª–µ–Ω —Ñ–∞–π–ª: {filepath}")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {filepath}: {e}")

async def run_replicate_model_async(model_id: str, input_params: dict) -> List[str]:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫ –º–æ–¥–µ–ª–∏ Replicate"""
    @tenacity.retry(
        wait=tenacity.wait_exponential(multiplier=1, min=2, max=10),
        stop=tenacity.stop_after_attempt(3),
        retry=tenacity.retry_if_exception_type(ReplicateError),
        reraise=True
    )
    async def _run():
        loop = asyncio.get_event_loop()
        replicate_client = replicate.Client(api_token=REPLICATE_API_TOKEN)
        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ —É–ª—å—Ç—Ä–∞-—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–π –º–æ–¥–µ–ª–∏ {model_id}")
        logger.debug(f"üì∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {input_params}")

        output = await loop.run_in_executor(
            None,
            lambda: replicate_client.run(model_id, input=input_params)
        )

        image_urls = []
        if isinstance(output, list):
            for item in output:
                if isinstance(item, str):
                    image_urls.append(item)
                elif hasattr(item, 'url'):
                    image_urls.append(item.url)

        logger.info(f"–ü–æ–ª—É—á–µ–Ω—ã URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {image_urls}")
        return image_urls

    return await _run()

async def upload_image_to_replicate(photo_path: str) -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç URL"""
    async with replicate_semaphore:
        loop = asyncio.get_event_loop()

        if not os.path.exists(photo_path):
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {photo_path}")

        file_size = os.path.getsize(photo_path)
        if file_size > MAX_FILE_SIZE_BYTES:
            raise ValueError(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {file_size / 1024 / 1024:.2f} MB")

        replicate_client = replicate.Client(api_token=REPLICATE_API_TOKEN)

        def upload_sync():
            with open(photo_path, 'rb') as f:
                return replicate_client.files.create(file=f)

        file_response = await loop.run_in_executor(None, upload_sync)
        image_url = file_response.urls.get('get')

        if not image_url:
            raise ValueError("Replicate –Ω–µ –≤–µ—Ä–Ω—É–ª URL")

        logger.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {image_url}")
        return image_url

def is_new_fast_flux_model(model_id: str, model_version: str = None) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª—å –Ω–æ–≤–æ–π –±—ã—Å—Ç—Ä–æ–π Flux –º–æ–¥–µ–ª—å—é"""
    if model_id and ("fastnew" in model_id.lower() or "fast-flux" in model_id.lower()):
        return True
    if model_version and len(model_version) == 64 and all(c in '0123456789abcdef' for c in model_version.lower()):
        return True
    if model_id and REPLICATE_USERNAME_OR_ORG_NAME and model_id.startswith(f"{REPLICATE_USERNAME_OR_ORG_NAME}/"):
        return True
    return False

# –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
process_prompt = process_prompt_async
upload_image_to_replicate = upload_image_to_replicate

# –°–ø–∏—Å–æ–∫ "22 –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"
PROFESSIONAL_MODELS_LIST = [
    "Flux-Realism-FineDetailed", "Flux-Super-Realism-LoRA", "Flux-RealismLora",
    "Flux-Ultra-Realism", "flux-dev-photorealism", "Canopus-LoRA-Flux-FaceRealism",
    "Flux-Super-Portrait-LoRA", "Flux-Portrait-LoRA", "Flux-Perfect-Face",
    "Flux-Skin-Real", "Flux-BetterSkin-LoRA", "Flux-Natural-Skin-Texture",
    "frosting_lane_flux", "colorgrading", "flux-professional-lighting",
    "flux-professional-photography", "Fashion-Hut-Modeling-LoRA",
    "Flux-Realistic-People", "Flux-Hyperrealistic-Portrait",
    "Flux-NSFW-uncensored", "Flux-Dev-Real-Anime", "flux-lora-the-explorer"
]

logger.info("üéØ –°–ò–°–¢–ï–ú–ê –ì–ï–ù–ï–†–ê–¶–ò–ò –ó–ê–ì–†–£–ñ–ï–ù–ê!")
logger.info("üì∏ 22 –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω—ã")
logger.info("üöÄ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–∞ –±–∞–∑–µ 5 –æ—Å–Ω–æ–≤–Ω—ã—Ö —è–¥–µ—Ä")
logger.info("‚ö° –ì–æ—Ç–æ–≤ –∫ —Å–æ–∑–¥–∞–Ω–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π!")